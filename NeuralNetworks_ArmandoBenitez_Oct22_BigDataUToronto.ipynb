{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References:\n",
    "\n",
    "- Neural network written in Python (NumPy) \n",
    "https://github.com/jorgenkg/python-neural-network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid function\n",
    "\n",
    "Sigmoid function can be defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_function( signal, derivative=False ):\n",
    "    # Prevent overflow.\n",
    "    signal = np.clip( signal, -500, 500 )\n",
    "    \n",
    "    # Calculate activation signal\n",
    "    signal = expit( signal )\n",
    "    \n",
    "    if derivative:\n",
    "        # Return the partial derivation of the activation function\n",
    "        return np.multiply(signal, 1-signal)\n",
    "    else:\n",
    "        # Return the activation signal\n",
    "        return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    def __init__(self, n_inputs, n_outputs, n_hiddens, n_hidden_layers, activation_functions ):\n",
    "        self.n_inputs = n_inputs                # Number of network input signals\n",
    "        self.n_outputs = n_outputs              # Number of desired outputs from the network\n",
    "        self.n_hiddens = n_hiddens              # Number of nodes in each hidden layer\n",
    "        self.n_hidden_layers = n_hidden_layers  # Number of hidden layers in the network\n",
    "        self.activation_functions = activation_functions\n",
    "        \n",
    "        assert len(activation_functions)==(n_hidden_layers+1), \"Requires \"+(n_hidden_layers+1)+\" activation functions, got: \"+len(activation_functions)+\".\"\n",
    "        \n",
    "        if n_hidden_layers == 0:\n",
    "            # Count the necessary number of weights for the input->output connection.\n",
    "            # input -> [] -> output\n",
    "            self.n_weights = ((n_inputs+1)*n_outputs)\n",
    "        else:\n",
    "            # Count the necessary number of weights summed over all the layers.\n",
    "            # input -> [n_hiddens -> n_hiddens] -> output\n",
    "            self.n_weights = (n_inputs+1)*n_hiddens+\\\n",
    "                             (n_hiddens**2+n_hiddens)*(n_hidden_layers-1)+\\\n",
    "                             n_hiddens*n_outputs+n_outputs\n",
    "        \n",
    "        # Initialize the network with new randomized weights\n",
    "        self.set_weights( self.generate_weights() )\n",
    "    #end\n",
    "    \n",
    "    \n",
    "    def generate_weights(self, low=-0.1, high=0.1):\n",
    "        # Generate new random weights for all the connections in the network\n",
    "        if not False:\n",
    "            # Support NumPy\n",
    "            return [random.uniform(low,high) for _ in xrange(self.n_weights)]\n",
    "        else:\n",
    "            return np.random.uniform(low, high, size=(1,self.n_weights)).tolist()[0]\n",
    "    #end\n",
    "    \n",
    "    \n",
    "    def unpack(self, weight_list ):\n",
    "        # This method will create a list of weight matrices. Each list element\n",
    "        # corresponds to the connection between two layers.\n",
    "        if self.n_hidden_layers == 0:\n",
    "            return [ np.array(weight_list).reshape(self.n_inputs+1,self.n_outputs) ]\n",
    "        else:\n",
    "            weight_layers = [ np.array(weight_list[:(self.n_inputs+1)*self.n_hiddens]).reshape(self.n_inputs+1,self.n_hiddens) ]\n",
    "            weight_layers += [ np.array(weight_list[(self.n_inputs+1)*self.n_hiddens+(i*(self.n_hiddens**2+self.n_hiddens)):(self.n_inputs+1)*self.n_hiddens+((i+1)*(self.n_hiddens**2+self.n_hiddens))]).reshape(self.n_hiddens+1,self.n_hiddens) for i in xrange(self.n_hidden_layers-1) ]\n",
    "            weight_layers += [ np.array(weight_list[(self.n_inputs+1)*self.n_hiddens+((self.n_hidden_layers-1)*(self.n_hiddens**2+self.n_hiddens)):]).reshape(self.n_hiddens+1,self.n_outputs) ]\n",
    "            \n",
    "        return weight_layers\n",
    "    #end\n",
    "    \n",
    "    \n",
    "    def set_weights(self, weight_list ):\n",
    "        # This is a helper method for setting the network weights to a previously defined list.\n",
    "        # This is useful for utilizing a previously optimized neural network weight set.\n",
    "        self.weights = self.unpack( weight_list )\n",
    "    #end\n",
    "    \n",
    "    \n",
    "    def get_weights(self, ):\n",
    "        # This will stack all the weights in the network on a list, which may be saved to the disk.\n",
    "        return [w for l in self.weights for w in l.flat]\n",
    "    #end\n",
    "    \n",
    "    def backpropagation(self, trainingset, ERROR_LIMIT=1e-3, learning_rate=0.3, momentum_factor=0.9  ):\n",
    "        def addBias(A):\n",
    "            # Add 1 as bias.\n",
    "            return np.hstack(( np.ones((A.shape[0],1)), A ))\n",
    "        #end addBias\n",
    "        \n",
    "        assert trainingset[0].features.shape[0] == self.n_inputs, \"ERROR: input size varies from the defined input setting\"\n",
    "        assert trainingset[0].targets.shape[0] == self.n_outputs, \"ERROR: output size varies from the defined output setting\"\n",
    "        \n",
    "        training_data = np.array( [instance.features for instance in trainingset ] )\n",
    "        training_targets = np.array( [instance.targets for instance in trainingset ] )\n",
    "        \n",
    "        MSE      = ( ) # inf\n",
    "        neterror = None\n",
    "        momentum = collections.defaultdict( int )\n",
    "        \n",
    "        epoch = 0\n",
    "        while MSE > ERROR_LIMIT:\n",
    "            epoch += 1\n",
    "            \n",
    "            input_layers      = self.update( training_data, trace=True )\n",
    "            out               = input_layers[-1]\n",
    "                              \n",
    "            error             = training_targets - out\n",
    "            delta             = error\n",
    "            MSE               = np.mean( np.power(error,2) )\n",
    "            \n",
    "            \n",
    "            loop  = itertools.izip(\n",
    "                            xrange(len(self.weights)-1, -1, -1),\n",
    "                            reversed(self.weights),\n",
    "                            reversed(input_layers[:-1]),\n",
    "                        )\n",
    "\n",
    "            \n",
    "            for i, weight_layer, input_signals in loop:\n",
    "                # Loop over the weight layers in reversed order to calculate the deltas\n",
    "                \n",
    "                # Calculate weight change \n",
    "                dW = learning_rate * np.dot( addBias(input_signals).T, delta ) + momentum_factor * momentum[i]\n",
    "                \n",
    "                if i!= 0:\n",
    "                    \"\"\"Do not calculate the delta unnecessarily.\"\"\"\n",
    "                    # Skipping the bias weight during calculation.\n",
    "                    weight_delta = np.dot( delta, weight_layer[1:,:].T )\n",
    "            \n",
    "                    # Calculate the delta for the subsequent layer\n",
    "                    delta = np.multiply(  weight_delta, self.activation_functions[i-1]( input_signals, derivative=True) )\n",
    "                \n",
    "                # Store the momentum\n",
    "                momentum[i] = dW\n",
    "                \n",
    "                # Update the weights\n",
    "                self.weights[ i ] += dW\n",
    "            \n",
    "            if epoch%1000==0:\n",
    "                # Show the current training status\n",
    "                print (\"* current network error (MSE):\", MSE)\n",
    "        \n",
    "        print (\"* Converged to error bound (%.4g) with MSE = %.4g.\" % ( ERROR_LIMIT, MSE ))\n",
    "        print (\"* Trained for %d epochs.\" % epoch)\n",
    "    # end backprop\n",
    "    \n",
    "    \n",
    "    def update(self, input_values, trace=False ):\n",
    "        # This is a forward operation in the network. This is how we calculate the network output\n",
    "        # from a set of input signals.\n",
    "        \n",
    "        output = input_values\n",
    "        if trace: tracelist = [ output ]\n",
    "        \n",
    "        for i, weight_layer in enumerate(self.weights):\n",
    "            # Loop over the network layers and calculate the output\n",
    "            output = np.dot( output, weight_layer[1:,:] ) + weight_layer[0:1,:] # implicit bias\n",
    "            output = self.activation_functions[i]( output )\n",
    "            if trace: tracelist.append( output )\n",
    "        \n",
    "        if trace: return tracelist\n",
    "        \n",
    "        return output\n",
    "    #end\n",
    "    \n",
    "    \n",
    "    def save_to_file(self, filename = \"network.pkl\" ):\n",
    "        import cPickle\n",
    "        \"\"\"\n",
    "        This save method pickles the parameters of the current network into a \n",
    "        binary file for persistant storage.\n",
    "        \"\"\"\n",
    "        with open( filename , 'wb') as file:\n",
    "            store_dict = {\n",
    "                \"n_inputs\"             : self.n_inputs,\n",
    "                \"n_outputs\"            : self.n_outputs,\n",
    "                \"n_hiddens\"            : self.n_hiddens,\n",
    "                \"n_hidden_layers\"      : self.n_hidden_layers,\n",
    "                \"activation_functions\" : self.activation_functions,\n",
    "                \"n_weights\"            : self.n_weights,\n",
    "                \"weights\"              : self.weights\n",
    "\n",
    "            }\n",
    "            cPickle.dump( store_dict, file, 2 )\n",
    "    #end\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_from_file( filename = \"network.pkl\" ):\n",
    "        \"\"\"\n",
    "        Load the complete configuration of a previously stored network.\n",
    "        \"\"\"\n",
    "        network = NeuralNet( 0, 0, 0, 0, [0] )\n",
    "        \n",
    "        with open( filename , 'rb') as file:\n",
    "            import cPickle\n",
    "            store_dict = cPickle.load(file)\n",
    "            \n",
    "            network.n_inputs             = store_dict[\"n_inputs\"]            \n",
    "            network.n_outputs            = store_dict[\"n_outputs\"]           \n",
    "            network.n_hiddens            = store_dict[\"n_hiddens\"]           \n",
    "            network.n_hidden_layers      = store_dict[\"n_hidden_layers\"]     \n",
    "            network.n_weights            = store_dict[\"n_weights\"]           \n",
    "            network.weights              = store_dict[\"weights\"]             \n",
    "            network.activation_functions = store_dict[\"activation_functions\"]\n",
    "        \n",
    "        return network\n",
    "    #end\n",
    "#end class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Instance:\n",
    "    # This is a simple encapsulation of a `input signal : output signal`\n",
    "    # pair in out training set.\n",
    "    def __init__(self, features, target):\n",
    "        self.features = np.array(features)\n",
    "        self.targets = np.array(target)\n",
    "#endclass Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('* current network error (MSE):', 0.25000003146401617)\n",
      "('* current network error (MSE):', 0.25000007059644125)\n",
      "('* current network error (MSE):', 0.2499999292608644)\n",
      "('* current network error (MSE):', 0.24999999046037724)\n",
      "('* current network error (MSE):', 0.24999978602240952)\n",
      "('* current network error (MSE):', 0.24995652224122622)\n",
      "('* current network error (MSE):', 0.2528143651148077)\n",
      "('* current network error (MSE):', 0.00065143052328386366)\n",
      "* Converged to error bound (0.0001) with MSE = 9.997e-05.\n",
      "* Trained for 8638 epochs.\n",
      "(array([0, 0]), array([[ 0.0104904]]), 'target:', array([0]))\n",
      "(array([0, 1]), array([[ 0.99006937]]), 'target:', array([1]))\n",
      "(array([1, 0]), array([[ 0.99006937]]), 'target:', array([1]))\n",
      "(array([1, 1]), array([[ 0.00959219]]), 'target:', array([0]))\n"
     ]
    }
   ],
   "source": [
    "# two training sets\n",
    "training_one =  [ Instance( [0,0], [0] ), Instance( [0,1], [1] ), Instance( [1,0], [1] ), Instance( [1,1], [0] ) ]\n",
    "\n",
    "n_inputs = 2\n",
    "n_outputs = 1\n",
    "n_hiddens = 2\n",
    "n_hidden_layers = 1\n",
    "\n",
    "# specify activation functions per layer eg: [ hidden_layer_1, hidden_layer_2, output_layer ]\n",
    "activation_functions = [ sigmoid_function ]*n_hidden_layers + [ sigmoid_function ]\n",
    "\n",
    "# initialize the neural network\n",
    "network = NeuralNet(n_inputs, n_outputs, n_hiddens, n_hidden_layers, activation_functions)\n",
    "\n",
    "# start training on test set one\n",
    "network.backpropagation(training_one, ERROR_LIMIT=1e-4, learning_rate=0.3, momentum_factor=0.9  )\n",
    "\n",
    "# save the trained network\n",
    "network.save_to_file( \"trained_configuration.pkl\" )\n",
    "\n",
    "# load a stored network configuration\n",
    "# network = NeuralNet.load_from_file( \"trained_configuration.pkl\" )\n",
    "\n",
    "# print out the result\n",
    "for instance in training_one:\n",
    "    print (instance.features, network.update( np.array([instance.features]) ), \"target:\", instance.targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AND Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Converged to error bound (0.0001) with MSE = 8.597e-05.\n",
      "* Trained for 41 epochs.\n",
      "(array([0, 0]), array([[ 0.01551647]]), 'target:', array([0]))\n",
      "(array([0, 1]), array([[ 0.99589695]]), 'target:', array([1]))\n",
      "(array([1, 0]), array([[ 0.99588844]]), 'target:', array([1]))\n",
      "(array([1, 1]), array([[ 0.99964026]]), 'target:', array([1]))\n"
     ]
    }
   ],
   "source": [
    "#AND\n",
    "# two training sets\n",
    "training_one =  [ Instance( [0,0], [0] ), Instance( [0,1], [1] ), Instance( [1,0], [1] ), Instance( [1,1], [1] ) ]\n",
    "\n",
    "n_inputs = 2\n",
    "n_outputs = 1\n",
    "n_hiddens = 2\n",
    "n_hidden_layers = 1\n",
    "\n",
    "# specify activation functions per layer eg: [ hidden_layer_1, hidden_layer_2, output_layer ]\n",
    "activation_functions = [ sigmoid_function ]*n_hidden_layers + [ sigmoid_function ]\n",
    "\n",
    "# initialize the neural network\n",
    "network = NeuralNet(n_inputs, n_outputs, n_hiddens, n_hidden_layers, activation_functions)\n",
    "\n",
    "# start training on test set one\n",
    "network.backpropagation(training_one, ERROR_LIMIT=1e-4, learning_rate=0.3, momentum_factor=0.9  )\n",
    "\n",
    "# save the trained network\n",
    "network.save_to_file( \"trained_configuration.pkl\" )\n",
    "\n",
    "# load a stored network configuration\n",
    "# network = NeuralNet.load_from_file( \"trained_configuration.pkl\" )\n",
    "\n",
    "# print out the result\n",
    "for instance in training_one:\n",
    "    print (instance.features, network.update( np.array([instance.features]) ), \"target:\", instance.targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two output units "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('* current network error (MSE):', 0.24999993034739548)\n",
      "('* current network error (MSE):', 0.24999992527570319)\n",
      "('* current network error (MSE):', 0.24999713340065544)\n",
      "('* current network error (MSE):', 0.25045463536240126)\n",
      "('* current network error (MSE):', 0.24856211966753305)\n",
      "('* current network error (MSE):', 0.24623664555759966)\n",
      "('* current network error (MSE):', 0.23654263635497247)\n",
      "* Converged to error bound (0.0001) with MSE = 8.636e-05.\n",
      "* Trained for 7935 epochs.\n",
      "(array([0, 0]), array([[  1.39311024e-18,   1.40094718e-18]]), 'target:', array([0, 0]))\n",
      "(array([0, 1]), array([[ 0.98831858,  0.9883123 ]]), 'target:', array([1, 1]))\n",
      "(array([1, 0]), array([[ 0.98831858,  0.9883123 ]]), 'target:', array([1, 1]))\n",
      "(array([1, 1]), array([[ 0.01576   ,  0.01576458]]), 'target:', array([0, 0]))\n"
     ]
    }
   ],
   "source": [
    "training_two =  [ Instance( [0,0], [0,0] ), Instance( [0,1], [1,1] ), Instance( [1,0], [1,1] ), Instance( [1,1], [0,0] ) ]\n",
    "\n",
    "n_inputs = 2\n",
    "n_outputs = 2\n",
    "n_hiddens = 2\n",
    "n_hidden_layers = 1\n",
    "\n",
    "# specify activation functions per layer eg: [ hidden_layer_1, hidden_layer_2, output_layer ]\n",
    "activation_functions = [ sigmoid_function ]*n_hidden_layers + [ sigmoid_function ]\n",
    "\n",
    "# initialize the neural network\n",
    "network = NeuralNet(n_inputs, n_outputs, n_hiddens, n_hidden_layers, activation_functions)\n",
    "\n",
    "# start training on test set one\n",
    "network.backpropagation(training_two, ERROR_LIMIT=1e-4, learning_rate=0.3, momentum_factor=0.9  )\n",
    "\n",
    "# save the trained network\n",
    "network.save_to_file( \"trained_configuration.pkl\" )\n",
    "\n",
    "# load a stored network configuration\n",
    "# network = NeuralNet.load_from_file( \"trained_configuration.pkl\" )\n",
    "\n",
    "# print out the result\n",
    "for instance in training_two:\n",
    "    print (instance.features, network.update( np.array([instance.features]) ), \"target:\", instance.targets)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
